{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "Due to the dimensions of this dataset, it was considered better to have a separate notebook for data Wrangling. At this stage I tried to get a dataset clean and tiddy enough for the subsequent analysis work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "Open `pisa2012.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (15,16,17,21,22,23,24,25,26,30,31,36,37,45,65,123,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,475) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "pisa_df_ = pd.read_csv('pisa2012.csv', encoding='windows-1252') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are problems to read certain columns. I will try to get the type of these columns and reopen the csv specifying the type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dtype_series = pisa_df_.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a series with the types of each column, I will save it as a `pkl` file so that the next time I open this notebook, I'll just import the type of each columns and specify it when reading `pisa2012.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dtype_series.to_pickle('col_dtype.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `col_dtype.pkl` and convert it to a dictionary in order to open `pisa2012.csv` successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_dtype_series = pd.read_pickle(\"col_dtype.pkl\")\n",
    "col_dtype_dict = col_dtype_series.to_dict()\n",
    "\n",
    "# Read pisa2012.csv and pisadict2012.csv\n",
    "pisa_df = pd.read_csv('pisa2012.csv', encoding='windows-1252', dtype= col_dtype_dict)\n",
    "pisa_csv = pd.read_csv('pisadict2012.csv', encoding='windows-1252')\n",
    "\n",
    "# Convert pisa_csv to a dictionary\n",
    "pisa_dict = pd.Series(pisa_csv.x.values, index = pisa_csv['Unnamed: 0']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(485490, 636)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CNT</th>\n",
       "      <th>SUBNATIO</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>OECD</th>\n",
       "      <th>NC</th>\n",
       "      <th>SCHOOLID</th>\n",
       "      <th>STIDSTD</th>\n",
       "      <th>ST01Q01</th>\n",
       "      <th>ST02Q01</th>\n",
       "      <th>...</th>\n",
       "      <th>W_FSTR75</th>\n",
       "      <th>W_FSTR76</th>\n",
       "      <th>W_FSTR77</th>\n",
       "      <th>W_FSTR78</th>\n",
       "      <th>W_FSTR79</th>\n",
       "      <th>W_FSTR80</th>\n",
       "      <th>WVARSTRR</th>\n",
       "      <th>VAR_UNIT</th>\n",
       "      <th>SENWGT_STU</th>\n",
       "      <th>VER_STU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385011</th>\n",
       "      <td>385012</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>6200000</td>\n",
       "      <td>PRT0006</td>\n",
       "      <td>OECD</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>52</td>\n",
       "      <td>1483</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3668</td>\n",
       "      <td>2.4556</td>\n",
       "      <td>7.3668</td>\n",
       "      <td>7.3668</td>\n",
       "      <td>2.4556</td>\n",
       "      <td>2.4556</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>22NOV13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448343</th>\n",
       "      <td>448344</td>\n",
       "      <td>Chinese Taipei</td>\n",
       "      <td>1580000</td>\n",
       "      <td>TAP9797</td>\n",
       "      <td>Non-OECD</td>\n",
       "      <td>Chinese Taipei</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.7750</td>\n",
       "      <td>29.7750</td>\n",
       "      <td>29.7750</td>\n",
       "      <td>29.7750</td>\n",
       "      <td>29.7750</td>\n",
       "      <td>29.7750</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>22NOV13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177286</th>\n",
       "      <td>177287</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2460000</td>\n",
       "      <td>FIN0017</td>\n",
       "      <td>OECD</td>\n",
       "      <td>Finland</td>\n",
       "      <td>58</td>\n",
       "      <td>1612</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4238</td>\n",
       "      <td>1.4373</td>\n",
       "      <td>1.4238</td>\n",
       "      <td>4.5938</td>\n",
       "      <td>4.5359</td>\n",
       "      <td>1.5120</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>22NOV13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             CNT  SUBNATIO  STRATUM      OECD  \\\n",
       "385011      385012        Portugal   6200000  PRT0006      OECD   \n",
       "448343      448344  Chinese Taipei   1580000  TAP9797  Non-OECD   \n",
       "177286      177287         Finland   2460000  FIN0017      OECD   \n",
       "\n",
       "                     NC  SCHOOLID  STIDSTD  ST01Q01  ST02Q01   ...     \\\n",
       "385011        Portugal         52     1483        7      1.0   ...      \n",
       "448343  Chinese Taipei          1       13       10      2.0   ...      \n",
       "177286          Finland        58     1612        9      1.0   ...      \n",
       "\n",
       "        W_FSTR75  W_FSTR76 W_FSTR77 W_FSTR78  W_FSTR79 W_FSTR80 WVARSTRR  \\\n",
       "385011    7.3668    2.4556   7.3668   7.3668    2.4556   2.4556       60   \n",
       "448343   29.7750   29.7750  29.7750  29.7750   29.7750  29.7750       58   \n",
       "177286    1.4238    1.4373   1.4238   4.5938    4.5359   1.5120       17   \n",
       "\n",
       "       VAR_UNIT SENWGT_STU  VER_STU  \n",
       "385011        2     0.0511  22NOV13  \n",
       "448343        1     0.2054  22NOV13  \n",
       "177286        2     0.0491  22NOV13  \n",
       "\n",
       "[3 rows x 636 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a general view of this df\n",
    "print(pisa_df.shape)\n",
    "pisa_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most striking things about this df is the number of columns it has. Working with so many columns would be an error, since many of these columns will not be useful to answer the questions that we want to answer or look for the insights we want. That's why, it will be best to remove those columns. In order to do this, first we have to give a view to each column and formulate the points that interest us, in order to define which columns will not be revelant to our work.\n",
    "\n",
    "...\n",
    "\n",
    "After seeing each column to know what data they provide, I have written down the following points that I find interesting:\n",
    "\n",
    "- What are the differences between the results of boys and girls?\n",
    "- Are there statistically significant differences between foreign students and local students?\n",
    "- Is there any relationship between students who arrive late, skip a class or miss a whole school day and a lower performance on the study?\n",
    "- Is there any difference in results between students who have access to the internet and those who do not?\n",
    "- Is there any relationship between the economic-socio-cultural level of the student and his performance in the test?\n",
    "\n",
    "Keeping this in mind, and after having read column by column, the columns that are of interest and useful to resolve these points are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STIDSTD Student ID\n",
      "ST04Q01 Gender\n",
      "CNT Country code 3-character\n",
      "ESCS Index of economic, social and cultural status\n",
      "PV1SCIE Plausible value 1 in science\n",
      "PV1READ Plausible value 1 in reading\n",
      "PV1MATH Plausible value 1 in mathematics\n",
      "IMMIG Immigration status\n",
      "ST08Q01 Truancy - Late for School\n",
      "ST09Q01 Truancy - Skip whole school day\n",
      "ST115Q01 Truancy - Skip classes within school day\n",
      "IC01Q04 At Home - Internet connection\n",
      "ST26Q06 Possessions - Internet\n"
     ]
    }
   ],
   "source": [
    "all_cols = ['STIDSTD', 'ST04Q01', 'CNT', 'ESCS', 'PV1SCIE', 'PV1READ',  'PV1MATH', \n",
    "             'IMMIG', 'ST08Q01', 'ST09Q01', 'ST115Q01', 'IC01Q04', 'ST26Q06']\n",
    "\n",
    "# Print each column\n",
    "for col_to_keep in all_cols:\n",
    "    print(col_to_keep, pisa_dict[col_to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df with needed columns\n",
    "all_cols_df = pisa_df[all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 485490 entries, 0 to 485489\n",
      "Data columns (total 13 columns):\n",
      "STIDSTD     485490 non-null int64\n",
      "ST04Q01     485490 non-null object\n",
      "CNT         485490 non-null object\n",
      "ESCS        473648 non-null float64\n",
      "PV1SCIE     485490 non-null float64\n",
      "PV1READ     485490 non-null float64\n",
      "PV1MATH     485490 non-null float64\n",
      "IMMIG       471793 non-null object\n",
      "ST08Q01     479143 non-null object\n",
      "ST09Q01     479131 non-null object\n",
      "ST115Q01    479269 non-null float64\n",
      "IC01Q04     297305 non-null object\n",
      "ST26Q06     473182 non-null object\n",
      "dtypes: float64(5), int64(1), object(7)\n",
      "memory usage: 48.2+ MB\n"
     ]
    }
   ],
   "source": [
    "all_cols_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________ \n",
      " STIDSTD Student ID [    1     2     3 ... 33804 33805 33806]\n",
      "________________________________________________________________________________ \n",
      " ST04Q01 Gender ['Female' 'Male']\n",
      "________________________________________________________________________________ \n",
      " CNT Country code 3-character ['Albania' 'United Arab Emirates' 'Argentina' 'Australia' 'Austria'\n",
      " 'Belgium' 'Bulgaria' 'Brazil' 'Canada' 'Switzerland' 'Chile' 'Colombia'\n",
      " 'Costa Rica' 'Czech Republic' 'Germany' 'Denmark' 'Spain' 'Estonia'\n",
      " 'Finland' 'France' 'United Kingdom' 'Greece' 'Hong Kong-China' 'Croatia'\n",
      " 'Hungary' 'Indonesia' 'Ireland' 'Iceland' 'Israel' 'Italy' 'Jordan'\n",
      " 'Japan' 'Kazakhstan' 'Korea' 'Liechtenstein' 'Lithuania' 'Luxembourg'\n",
      " 'Latvia' 'Macao-China' 'Mexico' 'Montenegro' 'Malaysia' 'Netherlands'\n",
      " 'Norway' 'New Zealand' 'Peru' 'Poland' 'Portugal' 'Qatar'\n",
      " 'China-Shanghai' 'Perm(Russian Federation)' 'Florida (USA)'\n",
      " 'Connecticut (USA)' 'Massachusetts (USA)' 'Romania' 'Russian Federation'\n",
      " 'Singapore' 'Serbia' 'Slovak Republic' 'Slovenia' 'Sweden'\n",
      " 'Chinese Taipei' 'Thailand' 'Tunisia' 'Turkey' 'Uruguay'\n",
      " 'United States of America' 'Vietnam']\n",
      "________________________________________________________________________________ \n",
      " ESCS Index of economic, social and cultural status [  nan  0.65  0.72 -0.09  1.08 -0.24  0.25  0.52 -0.04  1.5  -0.13 -0.95\n",
      "  0.4   0.74  0.38  1.41  1.19  0.95 -0.4   0.2   0.86  0.75  0.64  0.5\n",
      "  0.79 -0.84  0.33  0.02 -0.01  1.72 -0.06  0.59  1.21  0.81  0.93  2.41\n",
      " -1.07  0.58  2.17  1.2   1.33  1.26  2.13  0.83  1.09  1.92  1.4   1.14\n",
      "  0.66  1.13  2.18  0.82  0.78 -2.22  0.35  2.24 -0.1   0.98  0.99  1.49\n",
      "  0.68  0.51 -0.05  1.36  1.32  1.06  1.86 -0.3   0.85  1.1   0.6   1.27\n",
      "  1.64  1.56  1.16  0.32  0.88 -0.11 -1.02  0.1   0.45 -0.66 -0.49  0.05\n",
      " -0.56  1.01 -0.76  0.42  0.28  0.73  0.43 -0.2  -0.58 -0.07 -0.26 -0.41\n",
      " -0.77 -1.12  0.84 -0.89 -1.01  2.22 -0.17 -0.47  0.62 -0.64 -0.28  0.18\n",
      " -0.62  0.39 -0.46 -0.52 -0.7   0.23  1.05  0.89  0.3   0.08  0.27  0.91\n",
      "  0.19  1.29  0.67  0.17  0.77 -0.34 -1.09  0.69  0.54 -1.03  0.22  0.34\n",
      " -0.03  0.24  0.09  0.44  1.02  1.28  0.37  0.53  0.61  1.    1.35  0.71\n",
      "  0.76 -1.59 -0.02 -0.65 -0.54 -1.32 -0.85  1.78 -1.9   1.81  1.97 -1.8\n",
      "  0.31  0.87 -0.55  0.13  0.57 -0.08 -2.03 -1.57  0.26 -0.9  -0.25 -0.72\n",
      " -0.19 -2.31 -0.59 -0.79 -2.44 -1.21 -0.67 -0.15 -1.74 -2.94 -0.22  0.9\n",
      " -0.57 -0.43  0.96  1.46  0.11  0.01  1.23  0.48  0.36  0.29 -0.21  1.03\n",
      "  1.68  1.12 -0.14  1.65  0.7   2.14  1.42  1.62  1.47 -0.71 -1.48 -1.46\n",
      " -1.4  -1.88 -0.12 -2.3  -0.35 -2.41 -1.58 -3.07  1.37  0.55 -3.18  0.21\n",
      "  0.63 -0.81  0.04 -0.53 -0.39 -0.99 -0.18 -0.16  0.15 -0.23 -1.68 -1.1\n",
      " -0.42  1.45  1.34  1.63  1.54  0.07  1.59  0.49  1.04  0.94 -0.32 -2.46\n",
      "  0.92  1.67  0.    1.66  1.15  1.38  0.12  2.49 -1.05  0.47  0.06 -0.6\n",
      " -1.43 -1.67 -1.71 -0.78 -2.61  0.41 -2.35 -1.16 -1.64  0.03 -1.34 -1.18\n",
      " -2.17 -0.96 -0.98  1.43  1.44  0.8   1.22 -1.08  1.82  1.48  1.99 -0.75\n",
      "  1.8   1.25 -0.33  2.34  2.2  -0.97  0.97  0.14  1.07 -0.48 -0.27 -0.29\n",
      "  1.7  -1.45  0.16 -1.31 -1.28 -1.66 -2.48 -1.56 -2.25 -2.57 -1.41 -2.38\n",
      " -2.66 -1.89 -2.54 -2.93 -1.11 -0.63 -2.85 -1.82 -0.68 -2.63  1.11 -0.93\n",
      " -1.19  1.89 -0.36  0.46 -2.19  0.56  1.71 -0.87  2.02  1.24 -1.95 -0.51\n",
      " -0.44 -1.06 -0.94 -0.86 -1.72 -2.   -2.21 -0.83 -1.13 -0.45 -2.56 -1.14\n",
      " -3.21 -0.61 -0.74 -1.65 -0.8   1.53  1.84  2.19 -0.31 -1.29  2.04  1.17\n",
      "  2.35 -1.47 -0.38  1.79  1.73  1.18  1.74  2.21 -0.73  1.3  -1.69 -1.27\n",
      "  1.85 -1.62 -1.75 -1.5  -0.91 -0.37 -1.44 -1.38 -3.01 -1.93 -1.2  -1.51\n",
      "  2.08 -2.32 -2.23  2.54 -2.09 -1.54  2.43  1.39  1.58 -1.   -1.3  -1.81\n",
      " -2.13 -0.69 -1.15 -2.02 -2.26 -2.01 -0.82 -1.49  2.07 -1.86 -1.55  1.52\n",
      "  2.36  2.5  -1.36 -1.85 -2.37 -0.88 -1.73 -1.76 -2.77 -2.04 -1.37 -1.61\n",
      " -1.17 -2.58 -2.65 -1.53 -2.72 -0.5  -1.63 -2.6   2.53  2.26  1.6   2.09\n",
      " -2.24 -2.7  -1.23 -2.91 -1.98 -2.12  1.77 -0.92 -1.39 -1.42 -2.11 -1.83\n",
      " -1.22 -2.47  2.47  2.4  -2.89 -2.59 -2.68  1.31 -1.6   1.76  1.61 -2.28\n",
      " -1.04 -1.87 -1.26 -1.52  1.57 -1.91 -2.07 -1.97 -1.77 -2.74  1.93 -1.79\n",
      " -1.33  2.16  2.73 -1.84 -2.14 -1.35  2.05 -2.18  1.83 -2.29  2.1   2.23\n",
      " -1.94 -2.9  -1.7  -2.05 -2.67  1.75  1.55  2.63  1.9  -2.08 -3.09 -1.92\n",
      "  2.03 -3.37  1.91 -1.99  2.3  -2.15 -1.78  1.94  2.   -2.87 -2.33 -2.8\n",
      " -3.28  1.88 -3.46 -1.24 -2.06 -3.41 -3.2  -2.34 -2.42  2.28 -2.45 -2.79\n",
      " -2.64 -2.69 -2.16 -2.4  -1.25  2.72 -2.75  1.95 -3.62  2.01  2.69  2.39\n",
      " -2.83 -3.08 -2.73 -2.27 -3.    1.51  2.12 -2.39  1.98 -2.71 -2.99 -2.36\n",
      " -2.55 -3.05 -3.24 -2.52 -1.96  1.69 -2.86 -2.62 -2.84 -3.31 -2.5  -2.49\n",
      " -3.19 -2.43 -2.51 -2.53 -2.76 -2.78 -2.2  -3.04 -3.15 -3.39 -2.1  -3.23\n",
      " -2.88 -2.81  2.46 -3.02 -2.97 -3.45 -2.96 -3.11 -3.17 -3.53 -2.92 -4.44\n",
      " -3.66 -2.82 -2.95 -3.03 -3.27 -3.61 -3.33 -3.47 -3.5  -3.32 -3.29 -3.3\n",
      " -2.98 -3.67 -3.69 -3.22 -3.7  -4.31 -3.57 -4.32 -3.12  2.6  -3.48 -3.26\n",
      " -3.68 -3.36  2.44  2.38  2.06  2.15 -3.81 -3.6  -3.74  2.42  2.11 -3.38\n",
      "  2.32  2.57  2.56  2.48  2.51  2.37  2.71  2.67  2.7   2.45 -3.78 -4.7\n",
      " -4.21 -3.98 -5.05  1.87 -4.03 -3.13 -4.09 -4.33 -4.25 -5.22 -4.93 -5.95\n",
      " -4.16 -4.83 -4.54 -3.16  2.88  2.61 -3.97 -5.1   2.59 -4.05 -4.2  -4.77\n",
      " -3.1  -3.56 -3.35 -3.58 -3.44 -3.49 -4.24 -3.4  -3.71 -3.14 -3.59 -3.06\n",
      " -3.75 -3.8  -3.79 -3.99 -3.25 -3.34 -4.46 -4.   -3.65 -3.52 -3.84 -3.55\n",
      " -4.67 -3.43 -4.23 -3.51 -4.17 -3.85 -3.77 -3.63 -3.82 -4.12 -3.87 -4.68\n",
      " -4.72 -3.83 -3.54 -3.92 -4.29 -3.72 -3.73 -4.18 -4.8  -4.22 -4.48 -4.58\n",
      " -3.9  -3.42  3.13  2.25  2.27  2.64  2.65  1.96  2.85  2.58  2.52  2.55\n",
      "  2.31 -5.32  2.29  2.62 -3.93 -4.96 -3.96 -4.27 -4.6  -4.55 -3.64 -4.19\n",
      " -4.3  -4.08 -3.86 -4.02 -4.01 -3.95 -4.11 -4.26 -4.52 -4.15 -4.1  -5.34\n",
      " -3.91 -4.57 -4.07 -4.06 -4.04  3.01  2.66  2.75 -5.3   2.33  2.76 -3.88\n",
      "  3.27 -4.43 -3.89 -4.88 -5.01 -4.14 -4.34 -4.35 -4.56 -3.76  2.78  2.79\n",
      "  2.87  2.68 -5.62 -5.33 -4.64 -4.42 -5.2   2.94 -4.62 -4.28 -4.66 -4.97\n",
      " -4.79 -4.89  3.21 -4.4  -4.61 -4.37 -4.47 -4.51 -4.36 -4.59 -4.13 -3.94\n",
      " -5.44 -4.45  2.82 -4.38 -5.63 -5.66  3.69 -5.02  2.92 -4.69 -4.49 -4.65\n",
      " -4.87 -4.73  3.12 -4.84 -5.11]\n",
      "________________________________________________________________________________ \n",
      " PV1SCIE Plausible value 1 in science [341.7009 548.9929 499.6643 ... 715.5352 690.3581 691.2906]\n",
      "________________________________________________________________________________ \n",
      " PV1READ Plausible value 1 in reading [249.5762 406.2936 401.21   ... 693.7544 612.0262 672.9741]\n",
      "________________________________________________________________________________ \n",
      " PV1MATH Plausible value 1 in mathematics [406.8469 486.1427 533.2684 ... 178.4624 169.8941 824.7468]\n",
      "________________________________________________________________________________ \n",
      " IMMIG Immigration status ['Native' nan 'Second-Generation' 'First-Generation']\n",
      "________________________________________________________________________________ \n",
      " ST08Q01 Truancy - Late for School ['None  ' 'One or two times  ' 'Three or four times  ' nan\n",
      " 'Five or more times  ']\n",
      "________________________________________________________________________________ \n",
      " ST09Q01 Truancy - Skip whole school day ['None  ' nan 'One or two times  ' 'Three or four times  '\n",
      " 'Five or more times  ']\n",
      "________________________________________________________________________________ \n",
      " ST115Q01 Truancy - Skip classes within school day [ 1.  2.  3. nan  4.]\n",
      "________________________________________________________________________________ \n",
      " IC01Q04 At Home - Internet connection [nan 'Yes, and I use it' 'No' 'Yes, but I don’t use it']\n",
      "________________________________________________________________________________ \n",
      " ST26Q06 Possessions - Internet ['No' 'Yes' nan]\n"
     ]
    }
   ],
   "source": [
    "# Get unique values for each column\n",
    "for col in all_cols_df.columns:\n",
    "    print (\"________\" * 10, \"\\n\", col, pisa_dict[col], all_cols_df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `STIDSTD` (student id) should be a string. We do not want to do mathematical operations with the id of the students.\n",
    "* In `CNT`, 'Perm(Russian Federation)' should be 'Russian Federation'; 'Macao-China', 'China-Shanghai', 'Hong Kong-China' -> 'China'; 'Florida (USA)', 'Connecticut (USA)', 'Massachusetts (USA)' -> 'United States of America'; Chinese Taipei' -> Taiwan.\n",
    "* We could change the numerical values of `ST115Q01` by the definition of those numbers.\n",
    "* `ST04Q01` is a categorical variable.\n",
    "* `IMMIG`, `IC01Q04`, `ST08Q01`, `ST09Q01` are categorical ordinal variables, not strings.\n",
    "* Values of `ST08Q01` and `ST09Q01` have more spaces than necessary. Example: 'None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'.\n",
    "* `ST26Q06` 'Possessions - Internet' and `IC01Q04` 'At Home - Internet connection' seem to represent the same.\n",
    "\n",
    "There are several columns that have null values. I decided that I will leave those columns as they are and I will take care of those null values depending on the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "**`STIDSTD` (student id) should be a string. We do not want to do mathematical operations with the id of the students.**\n",
    "\n",
    "**Define:** Change to `str` using `astype(str)`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "all_cols_df.STIDSTD = all_cols_df.STIDSTD.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df.STIDSTD.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In `CNT`, 'Perm(Russian Federation)' should be 'Russian Federation'; 'Macao-China', 'China-Shanghai', 'Hong Kong-China' -> 'China'; 'Florida (USA)', 'Connecticut (USA)', 'Massachusetts (USA)' -> 'United States of America'; Chinese Taipei' -> Taiwan.**\n",
    "\n",
    "**Define:** Use `replace`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols_df.CNT = all_cols_df.CNT.replace('Perm(Russian Federation)', 'Russian Federation')\n",
    "all_cols_df.CNT = all_cols_df.CNT.replace('Macao-China', 'China')\n",
    "all_cols_df.CNT = all_cols_df.CNT.replace('China-Shanghai', 'China')\n",
    "all_cols_df.CNT = all_cols_df.CNT.replace('Hong Kong-China', 'China')\n",
    "all_cols_df.CNT = all_cols_df.CNT.replace('Florida (USA)', 'United States of America')\n",
    "all_cols_df.CNT = all_cols_df.CNT.replace('Connecticut (USA)', 'United States of America')\n",
    "all_cols_df.CNT = all_cols_df.CNT.replace('Massachusetts (USA)', 'United States of America')\n",
    "all_cols_df.CNT = all_cols_df.CNT.replace('Chinese Taipei', 'Taiwan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Albania', 'United Arab Emirates', 'Argentina', 'Australia',\n",
       "       'Austria', 'Belgium', 'Bulgaria', 'Brazil', 'Canada',\n",
       "       'Switzerland', 'Chile', 'Colombia', 'Costa Rica', 'Czech Republic',\n",
       "       'Germany', 'Denmark', 'Spain', 'Estonia', 'Finland', 'France',\n",
       "       'United Kingdom', 'Greece', 'China', 'Croatia', 'Hungary',\n",
       "       'Indonesia', 'Ireland', 'Iceland', 'Israel', 'Italy', 'Jordan',\n",
       "       'Japan', 'Kazakhstan', 'Korea', 'Liechtenstein', 'Lithuania',\n",
       "       'Luxembourg', 'Latvia', 'Mexico', 'Montenegro', 'Malaysia',\n",
       "       'Netherlands', 'Norway', 'New Zealand', 'Peru', 'Poland',\n",
       "       'Portugal', 'Qatar', 'Russian Federation',\n",
       "       'United States of America', 'Romania', 'Singapore', 'Serbia',\n",
       "       'Slovak Republic', 'Slovenia', 'Sweden', 'Taiwan', 'Thailand',\n",
       "       'Tunisia', 'Turkey', 'Uruguay', 'Vietnam'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df.CNT.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We could change the numerical values of `ST115Q01` by the definition of those numbers.**\n",
    "\n",
    "**Define:** Use `replace`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# ST115Q01 replace\n",
    "all_cols_df.ST115Q01 = all_cols_df.ST115Q01.replace(1, 'Never') # In order to avoid mistakes, I'll write \"Never\"\n",
    "                                                                # instead of \"None\"\n",
    "all_cols_df.ST115Q01 = all_cols_df.ST115Q01.replace(2, 'One or Two Times')\n",
    "all_cols_df.ST115Q01 = all_cols_df.ST115Q01.replace(3, 'Three or Four Times')\n",
    "all_cols_df.ST115Q01 = all_cols_df.ST115Q01.replace(4, 'Five or More Times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Never', 'One or Two Times', 'Three or Four Times', nan,\n",
       "       'Five or More Times'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df.ST115Q01.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Values of `ST08Q01` and `ST09Q01` have more spaces than necessary. Example: 'None&nbsp;&nbsp;&nbsp;&nbsp;'.**\n",
    "\n",
    "**Define:** `Use replace`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ST08Q01\n",
    "all_cols_df.ST08Q01 = all_cols_df.ST08Q01.replace('None  ', 'Never')\n",
    "all_cols_df.ST08Q01 = all_cols_df.ST08Q01.replace('One or two times  ', 'One or Two Times')\n",
    "all_cols_df.ST08Q01 = all_cols_df.ST08Q01.replace('Three or four times  ', \"Three or Four Times\")\n",
    "all_cols_df.ST08Q01 = all_cols_df.ST08Q01.replace('Five or more times  ', 'Five or More Times')\n",
    "\n",
    "# ST09Q01\n",
    "all_cols_df.ST09Q01 = all_cols_df.ST09Q01.replace('None  ', 'Never')\n",
    "all_cols_df.ST09Q01 = all_cols_df.ST09Q01.replace('One or two times  ', 'One or Two Times')\n",
    "all_cols_df.ST09Q01 = all_cols_df.ST09Q01.replace('Three or four times  ', \"Three or Four Times\")\n",
    "all_cols_df.ST09Q01 = all_cols_df.ST09Q01.replace('Five or more times  ', 'Five or More Times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Never', 'One or Two Times', 'Three or Four Times', nan,\n",
       "       'Five or More Times'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df.ST08Q01.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Never', 'One or Two Times', 'Three or Four Times', nan,\n",
       "       'Five or More Times'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df.ST08Q01.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ST26Q06` 'Possessions - Internet' and `IC01Q04` 'At Home - Internet connection' seem to represent the same.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possessions - Internet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Yes    402040\n",
       "No      71142\n",
       "Name: ST26Q06, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pisa_dict['ST26Q06'])\n",
    "pisa_df.ST26Q06.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Home - Internet connection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Yes, and I use it          259762\n",
       "No                          30161\n",
       "Yes, but I don’t use it      7382\n",
       "Name: IC01Q04, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pisa_dict['IC01Q04'])\n",
    "pisa_df.IC01Q04.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ST26Q06` has more values than` IC01Q04`, but `IC01Q04` besides asking if the student has internet or not, ask if they use it. Since I want to know if access to the Internet has any relationship with the student's performance, then it is necessary to know not only if a student has internet at home, but also to know if they use it. Therefore, we will remove `ST26Q06` and we will keep` IC01Q04`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define:** Remove `ST26Q06` from df.\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "all_cols_df.drop('ST26Q06', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ST26Q06' in all_cols_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ST04Q01` is a categorical variable.**\n",
    "\n",
    "**Define:** Use `pd.api.types.CategoricalDtype`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "# Categories\n",
    "genders = [\"Female\", \"Male\"]\n",
    "gclasses = pd.api.types.CategoricalDtype(ordered = False, categories=genders)\n",
    "\n",
    "# Convert\n",
    "all_cols_df.ST04Q01 = all_cols_df.ST04Q01.astype(gclasses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________ \n",
      "Gender\n",
      "category\n",
      "(485490,)\n",
      "Female    245064\n",
      "Male      240426\n",
      "Name: ST04Q01, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def print_dtypes_value_count_shape(col):\n",
    "    print(\"____\"*10, \"\\n\" + pisa_dict[col])\n",
    "    print(all_cols_df[col].dtypes)\n",
    "    print(all_cols_df[col].shape)\n",
    "    print(all_cols_df[col].value_counts())\n",
    "    \n",
    "\n",
    "print_dtypes_value_count_shape('ST04Q01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`IMMIG`, `IC01Q04`, `ST08Q01`, `ST09Q01` are categorical ordinal variables, not strings.**\n",
    "\n",
    "**Define:** Use `pd.api.types.CategoricalDtype`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMMIG\n",
    "# Categories\n",
    "immigration_status = ['Native', 'First-Generation', 'Second-Generation']\n",
    "isclasses = pd.api.types.CategoricalDtype(ordered = True, categories=immigration_status)\n",
    "\n",
    "# Convert\n",
    "all_cols_df.IMMIG = all_cols_df.IMMIG.astype(isclasses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IC01Q04\n",
    "# Categories\n",
    "use_of_tech = ['Yes, and I use it', 'Yes, but I don’t use it', 'No']\n",
    "use_of_tech_classes = pd.api.types.CategoricalDtype(ordered = True, categories=use_of_tech)\n",
    "\n",
    "# Convert\n",
    "all_cols_df.IC01Q04 = all_cols_df.IC01Q04.astype(use_of_tech_classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ST08Q01\n",
    "late_for_school = ['Never', 'One or Two Times', 'Three or Four Times', 'Five or More Times']\n",
    "lclasses = pd.api.types.CategoricalDtype(ordered = True, categories=late_for_school)\n",
    "\n",
    "# Convert\n",
    "all_cols_df.ST08Q01 = all_cols_df.ST08Q01.astype(lclasses)\n",
    "all_cols_df.ST09Q01 = all_cols_df.ST09Q01.astype(lclasses)\n",
    "all_cols_df.ST115Q01 = all_cols_df.ST115Q01.astype(lclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________ \n",
      "Immigration status\n",
      "category\n",
      "(485490,)\n",
      "Native               417347\n",
      "Second-Generation     28268\n",
      "First-Generation      26178\n",
      "Name: IMMIG, dtype: int64\n",
      "________________________________________ \n",
      "At Home - Internet connection\n",
      "category\n",
      "(485490,)\n",
      "Yes, and I use it          259762\n",
      "No                          30161\n",
      "Yes, but I don’t use it      7382\n",
      "Name: IC01Q04, dtype: int64\n",
      "________________________________________ \n",
      "Truancy - Late for School\n",
      "category\n",
      "(485490,)\n",
      "Never                  306065\n",
      "One or Two Times       124380\n",
      "Three or Four Times     29817\n",
      "Five or More Times      18881\n",
      "Name: ST08Q01, dtype: int64\n",
      "________________________________________ \n",
      "Truancy - Skip whole school day\n",
      "category\n",
      "(485490,)\n",
      "Never                  385998\n",
      "One or Two Times        75969\n",
      "Three or Four Times     10882\n",
      "Five or More Times       6282\n",
      "Name: ST09Q01, dtype: int64\n",
      "________________________________________ \n",
      "Truancy - Skip classes within school day\n",
      "category\n",
      "(485490,)\n",
      "Never                  378576\n",
      "One or Two Times        81343\n",
      "Three or Four Times     12216\n",
      "Five or More Times       7134\n",
      "Name: ST115Q01, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat_ord_cols = ['IMMIG', 'IC01Q04', 'ST08Q01', 'ST09Q01', 'ST115Q01']\n",
    "\n",
    "for col in cat_ord_cols:\n",
    "    print_dtypes_value_count_shape(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns have difficult names to remember**\n",
    "\n",
    "**Define:** Use `rename`\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {'STIDSTD': 'student_id', 'CNT' : 'country', 'ST04Q01': 'gender', \n",
    "             'IMMIG': 'immig_status', 'IC01Q04': 'internet_home','ST08Q01': 'late_to_school', \n",
    "             'ST115Q01': 'skip_class_within_school', 'ST09Q01': 'skip_whole_school_day', \n",
    "             'PV1MATH': 'math_score', 'PV1READ': 'reading_score', 'PV1SCIE': 'science_score'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "all_cols_df.rename(columns = new_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's possible that to make an analysis taking geographic variables, we'll need to have a column of a continent or a global region, not just a country**\n",
    "\n",
    "**Define:** Create a dictionary linking every country to a global region\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent = {'Spain': 'Europe', 'Croatia': 'Europe', 'Hungary': 'Europe', 'Czech Republic': 'Europe',\n",
    "             'United Kingdom': 'Europe', 'Greece': 'Europe', 'Belgium': 'Europe', 'Bulgaria': 'Europe', \n",
    "             'Germany': 'Europe', 'Denmark': 'Europe', 'Estonia': 'Europe', 'Finland': 'Europe', 'France': 'Europe',\n",
    "             'Luxembourg': 'Europe', 'Latvia': 'Europe', 'Netherlands': 'Europe', 'Norway': 'Europe', \n",
    "             'Romania': 'Europe', 'Sweden': 'Europe', 'Russian Federation': 'Europe', 'Portugal': 'Europe',\n",
    "             'Poland': 'Europe', 'Liechtenstein': 'Europe', 'Lithuania': 'Europe', 'Ireland': 'Europe', \n",
    "             'Iceland': 'Europe', 'Italy': 'Europe', 'Slovenia': 'Europe', 'Austria': 'Europe', 'Albania': 'Europe',\n",
    "             'Montenegro': 'Europe', 'Slovak Republic': 'Europe', 'Serbia': 'Europe', 'Switzerland': 'Europe',\n",
    "             'Argentina': 'Latin America', 'Brazil': 'Latin America', 'Chile': 'Latin America', \n",
    "             'Colombia': 'Latin America', 'Costa Rica': 'Latin America', 'Mexico': 'Latin America', \n",
    "             'Peru': 'Latin America', 'Uruguay': 'Latin America', 'Tunisia': 'Middle East and Africa',\n",
    "             'United States of America': 'North America', 'Canada': 'North America',\n",
    "             'Australia': 'Oceania', 'New Zealand': 'Oceania', 'Israel': 'Middle East and Africa', 'Qatar': \n",
    "             'Middle East and Africa', 'Vietnam': 'Middle East and Africa', 'Jordan': 'Middle East and Africa', \n",
    "             'Turkey': 'Middle East and Africa', \n",
    "             'United Arab Emirates': 'Middle East and Africa', 'Taiwan': 'Asia', 'China': 'Asia', 'Japan': 'Asia', \n",
    "             'Korea': 'Asia', 'Singapore': 'Asia', 'Thailand': 'Asia', 'Malaysia': 'Asia', 'Indonesia': 'Asia', \n",
    "             'Kazakhstan': 'Asia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create global_region col\n",
    "all_cols_df['global_region'] = all_cols_df.apply(lambda row: continent[row.country], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert global_regions to a categorical type\n",
    "global_regions = ['Europe', 'Latin America', 'North America', 'Asia', 'Middle East and Africa', 'Oceania']\n",
    "region_classes = pd.api.types.CategoricalDtype(ordered = False, categories=global_regions)\n",
    "\n",
    "# Convert\n",
    "all_cols_df.global_region = all_cols_df.global_region.astype(region_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Europe                    233917\n",
       "Latin America              90799\n",
       "Asia                       61391\n",
       "Middle East and Africa     48773\n",
       "North America              31838\n",
       "Oceania                    18772\n",
       "Name: global_region, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df['global_region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['Europe', 'Latin America', 'North America', 'Asia',\n",
       "                  'Middle East and Africa', 'Oceania'],\n",
       "                 ordered=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df.global_region.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Due to the amount of data we have in this dataset, we consider it prudent to have a column called `comb_score`, which is the sum of the three scores obtained by the student.**\n",
    "\n",
    "**Define:** I'll create a new columns using `apply` and `np.sum`.\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "all_cols_df['comb_score'] = all_cols_df.apply(lambda row: \n",
    "                                         np.sum([row.math_score, row.reading_score, row.science_score]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>science_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>math_score</th>\n",
       "      <th>immig_status</th>\n",
       "      <th>late_to_school</th>\n",
       "      <th>skip_whole_school_day</th>\n",
       "      <th>skip_class_within_school</th>\n",
       "      <th>internet_home</th>\n",
       "      <th>global_region</th>\n",
       "      <th>comb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84353</th>\n",
       "      <td>9884</td>\n",
       "      <td>Female</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.59</td>\n",
       "      <td>525.1212</td>\n",
       "      <td>525.2018</td>\n",
       "      <td>499.1510</td>\n",
       "      <td>Native</td>\n",
       "      <td>Never</td>\n",
       "      <td>One or Two Times</td>\n",
       "      <td>Never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North America</td>\n",
       "      <td>1549.4740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185124</th>\n",
       "      <td>621</td>\n",
       "      <td>Female</td>\n",
       "      <td>France</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>562.0477</td>\n",
       "      <td>560.0720</td>\n",
       "      <td>535.0600</td>\n",
       "      <td>Native</td>\n",
       "      <td>One or Two Times</td>\n",
       "      <td>Never</td>\n",
       "      <td>Never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1657.1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144558</th>\n",
       "      <td>6457</td>\n",
       "      <td>Female</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>435.5091</td>\n",
       "      <td>487.8692</td>\n",
       "      <td>466.8251</td>\n",
       "      <td>Native</td>\n",
       "      <td>Never</td>\n",
       "      <td>Never</td>\n",
       "      <td>Never</td>\n",
       "      <td>Yes, and I use it</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1390.2034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       student_id  gender  country  ESCS  science_score  reading_score  \\\n",
       "84353        9884  Female   Canada  0.59       525.1212       525.2018   \n",
       "185124        621  Female   France -0.68       562.0477       560.0720   \n",
       "144558       6457  Female  Denmark -0.14       435.5091       487.8692   \n",
       "\n",
       "        math_score immig_status    late_to_school skip_whole_school_day  \\\n",
       "84353     499.1510       Native             Never      One or Two Times   \n",
       "185124    535.0600       Native  One or Two Times                 Never   \n",
       "144558    466.8251       Native             Never                 Never   \n",
       "\n",
       "       skip_class_within_school      internet_home  global_region  comb_score  \n",
       "84353                     Never                NaN  North America   1549.4740  \n",
       "185124                    Never                NaN         Europe   1657.1797  \n",
       "144558                    Never  Yes, and I use it         Europe   1390.2034  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check everything again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 485490 entries, 0 to 485489\n",
      "Data columns (total 14 columns):\n",
      "student_id                  485490 non-null object\n",
      "gender                      485490 non-null category\n",
      "country                     485490 non-null object\n",
      "ESCS                        473648 non-null float64\n",
      "science_score               485490 non-null float64\n",
      "reading_score               485490 non-null float64\n",
      "math_score                  485490 non-null float64\n",
      "immig_status                471793 non-null category\n",
      "late_to_school              479143 non-null category\n",
      "skip_whole_school_day       479131 non-null category\n",
      "skip_class_within_school    479269 non-null category\n",
      "internet_home               297305 non-null category\n",
      "global_region               485490 non-null category\n",
      "comb_score                  485490 non-null float64\n",
      "dtypes: category(7), float64(5), object(2)\n",
      "memory usage: 29.2+ MB\n"
     ]
    }
   ],
   "source": [
    "all_cols_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols_df.to_csv('clean_pisa_data.csv', index=False)\n",
    "\n",
    "# Export column types too\n",
    "clean_pisa_series = all_cols_df.dtypes\n",
    "clean_pisa_series.to_pickle('clean_pisa_cols.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
